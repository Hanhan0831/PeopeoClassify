{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T15:17:16.553617Z",
     "start_time": "2023-04-30T15:17:00.044194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2016-11-17 02:14:42.322' 0.0 -0.003 ... 1.146 -0.221 1]\n",
      " ['2016-11-17 02:14:42.334' 0.021 -0.003 ... 1.146 -0.221 1]\n",
      " ['2016-11-17 02:14:42.345' 0.043 -0.004 ... 1.146 -0.221 1]\n",
      " ...\n",
      " ['2016-11-23 12:50:51.367' 292.058 -0.042 ... 1.1 -0.209 48]\n",
      " ['2016-11-23 12:50:51.379' 292.058 -0.043 ... 1.1 -0.21 48]\n",
      " ['2016-11-23 12:50:51.392' 292.079 -0.043 ... 1.1 -0.21 48]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 初始化一个空的数据列表，用于存储数据和标签\n",
    "data_list = []\n",
    "\n",
    "# 遍历Experiment_1目录下的48个文件夹\n",
    "for user_id in range(1, 49):\n",
    "    user_folder = os.path.join(\"Experiment_1\", str(user_id))\n",
    "\n",
    "    # 遍历每个用户的8个视频文件\n",
    "    for video_id in range(1, 9):\n",
    "        video_file = os.path.join(user_folder, f\"video_{video_id}.csv\")\n",
    "\n",
    "        # 读取CSV文件，跳过第一行标题\n",
    "        df = pd.read_csv(video_file, skiprows=1, header=None)\n",
    "\n",
    "        # 为DataFrame添加列名\n",
    "        df.columns = [\"Timestamp\", \"PlaybackTime\", \"UnitQuaternion.x\", \"UnitQuaternion.y\", \"UnitQuaternion.z\",\n",
    "                      \"UnitQuaternion.w\", \"HmdPosition.x\", \"HmdPosition.y\", \"HmdPosition.z\"]\n",
    "\n",
    "        # 添加标签列，表示用户ID\n",
    "        df[\"User_ID\"] = user_id\n",
    "\n",
    "        # 将数据添加到数据列表中\n",
    "        data_list.append(df)\n",
    "\n",
    "# 合并所有数据到一个大的DataFrame\n",
    "all_data = pd.concat(data_list, ignore_index=True)\n",
    "\n",
    "# 转换为NumPy数组，以便进一步处理\n",
    "data_array = all_data.to_numpy()\n",
    "\n",
    "print(data_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T16:20:30.763643Z",
     "start_time": "2023-04-30T16:17:19.099588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892dd3c2e21c4063a2e59049324b28c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data array shape: (314880, 43)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def autocorr(x, max_lag):\n",
    "    result = np.correlate(x, x, mode='full')\n",
    "    result = result[result.size // 2:]\n",
    "    result /= result[0]\n",
    "    return result[:max_lag + 1]\n",
    "\n",
    "max_lag = 5\n",
    "sample_interval = 0.1\n",
    "num_features = 7\n",
    "samples_per_sec = 10\n",
    "\n",
    "# 初始化一个空的数据列表，用于存储特征和标签\n",
    "data_list = []\n",
    "\n",
    "# 遍历每个用户\n",
    "for user_id in tqdm(range(1, 49)):\n",
    "    # 遍历每个用户的每个视频\n",
    "    for video_id in range(1, 9):\n",
    "        df = data_array[data_array[:, -1] == user_id]\n",
    "        df = df[df[:, 1] >= (video_id - 1) * 100]\n",
    "        df = df[df[:, 1] < video_id * 100]\n",
    "\n",
    "        if df.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        # 对每一秒的数据进行处理\n",
    "        for sec in range(int(df[:, 1].min()), int(df[:, 1].max()) + 1):\n",
    "            df_sec = df[(df[:, 1] >= sec) & (df[:, 1] < sec + 1)]\n",
    "\n",
    "            # 对每秒的数据进行等间隔采样\n",
    "            df_resampled = pd.DataFrame(index=np.arange(0, 1, sample_interval))\n",
    "            for col in range(2, 2 + num_features):\n",
    "                df_resampled[str(col)] = np.interp(df_resampled.index, df_sec[:, 1].astype(float) - sec, df_sec[:, col].astype(float))\n",
    "\n",
    "            # 计算自相关特征\n",
    "            autocorr_features = []\n",
    "            for col in range(2, 2 + num_features):\n",
    "                autocorr_features.extend(autocorr(df_resampled[str(col)].values, max_lag))\n",
    "\n",
    "            # 添加这一秒的特征和标签到数据列表\n",
    "            for _ in range(samples_per_sec):\n",
    "                data_list.append([user_id] + autocorr_features)\n",
    "\n",
    "# 将数据列表转换为NumPy数组\n",
    "data_array_processed = np.array(data_list)\n",
    "\n",
    "print(\"Data array shape:\", data_array_processed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T16:20:42.402790Z",
     "start_time": "2023-04-30T16:20:42.388790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          1.          0.18908275 ...  0.62386738  0.5425764\n",
      "   0.48710233]\n",
      " [ 1.          1.          0.18908275 ...  0.62386738  0.5425764\n",
      "   0.48710233]\n",
      " [ 1.          1.          0.18908275 ...  0.62386738  0.5425764\n",
      "   0.48710233]\n",
      " ...\n",
      " [48.          1.          0.8761246  ...  0.69908592  0.5995308\n",
      "   0.49997569]\n",
      " [48.          1.          0.8761246  ...  0.69908592  0.5995308\n",
      "   0.49997569]\n",
      " [48.          1.          0.8761246  ...  0.69908592  0.5995308\n",
      "   0.49997569]]\n",
      "314880\n"
     ]
    }
   ],
   "source": [
    "print(data_array_processed)\n",
    "print(len(data_array_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-30T15:47:03.586940Z",
     "start_time": "2023-04-30T15:46:32.954846Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_8 (Bidirectio  (None, 42, 128)          33792     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 128)              98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 48)                6192      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,800\n",
      "Trainable params: 138,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "7872/7872 - 212s - loss: 3.4489 - accuracy: 0.0847 - val_loss: 3.2461 - val_accuracy: 0.1327 - 212s/epoch - 27ms/step\n",
      "Epoch 2/50\n",
      "7872/7872 - 206s - loss: 3.0345 - accuracy: 0.1834 - val_loss: 2.8442 - val_accuracy: 0.2290 - 206s/epoch - 26ms/step\n",
      "Epoch 3/50\n",
      "7872/7872 - 205s - loss: 2.7217 - accuracy: 0.2671 - val_loss: 2.5909 - val_accuracy: 0.2993 - 205s/epoch - 26ms/step\n",
      "Epoch 4/50\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 准备数据\n",
    "X = data_array_processed[:, 1:]\n",
    "y = data_array_processed[:, 0]\n",
    "\n",
    "# 数据归一化\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# 将标签减1，使其范围为0到47\n",
    "y = y - 1\n",
    "\n",
    "# 对标签进行one-hot编码\n",
    "y = np.eye(48)[y.astype(int)]\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# 为输入数据增加一个维度\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "# 创建双向LSTM模型\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dense(48, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
